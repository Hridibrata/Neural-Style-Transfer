{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural style transfer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNBAeY5hfB7w8VQhEJHGTpz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b4abbf9758a49349981e735824528a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2652406ac7f24dcfb4472d7a22456288",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2b80fbb31a5b4c78a7c63c0b470ac786",
              "IPY_MODEL_3fa792f34d0a479789f07b9dc8d1a96b"
            ]
          }
        },
        "2652406ac7f24dcfb4472d7a22456288": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b80fbb31a5b4c78a7c63c0b470ac786": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9782e931dc2345419830951433435a6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 574673361,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 574673361,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19798024ac8e4f0396e96157e4947337"
          }
        },
        "3fa792f34d0a479789f07b9dc8d1a96b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2efeac10cd6b4992b4a659889e0f31ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 548M/548M [00:05&lt;00:00, 106MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58b17aa163ca4a83b5e54fccf39b9df4"
          }
        },
        "9782e931dc2345419830951433435a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19798024ac8e4f0396e96157e4947337": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2efeac10cd6b4992b4a659889e0f31ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58b17aa163ca4a83b5e54fccf39b9df4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hridibrata/Neural-Style-Transfer/blob/master/neural_style_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AGz2KvYWZaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision as tv\n",
        "from PIL import Image\n",
        "import imageio\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MefT_WWWdYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_tensor = tv.transforms.Compose([\n",
        "                tv.transforms.Resize((512,512)),\n",
        "                tv.transforms.ToTensor(),\n",
        "                tv.transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[1, 1, 1]),\n",
        "            ])\n",
        "\n",
        "unload = tv.transforms.Compose([\n",
        "                tv.transforms.Normalize(mean=[-0.485,-0.456,-0.406],\n",
        "                                    std=[1,1,1]),                \n",
        "                tv.transforms.Lambda(lambda x: x.clamp(0,1))\n",
        "            ])\n",
        "to_image = tv.transforms.ToPILImage()\n",
        "\n",
        "style_img = '/content/udnie.jpg'\n",
        "input_img = '/content/chicago_resized.jpg'\n",
        "\n",
        "style_img = Image.open(style_img)\n",
        "input_img = Image.open(input_img)\n",
        "\n",
        "style_img = to_tensor(style_img)\n",
        "input_img = to_tensor(input_img)\n",
        "\n",
        "plt.imshow(style_img)\n",
        "plt.imshow(input_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWF8xTYGbIQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(module, x, y):\n",
        "#     print('here')\n",
        "    features.append(y)\n",
        "    \n",
        "def gram_matrix(x):\n",
        "    \n",
        "    b, c, h, w = x.size()\n",
        "    F = x.view(b,c,h*w)\n",
        "    G = torch.bmm(F, F.transpose(1,2))/(h*w)\n",
        "    return G"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJbPEIeIp_Er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "2b4abbf9758a49349981e735824528a8",
            "2652406ac7f24dcfb4472d7a22456288",
            "2b80fbb31a5b4c78a7c63c0b470ac786",
            "3fa792f34d0a479789f07b9dc8d1a96b",
            "9782e931dc2345419830951433435a6c",
            "19798024ac8e4f0396e96157e4947337",
            "2efeac10cd6b4992b4a659889e0f31ca",
            "58b17aa163ca4a83b5e54fccf39b9df4"
          ]
        },
        "outputId": "1952fd39-6cd8-48cd-b161-a4d527c59eef"
      },
      "source": [
        "VGG = tv.models.vgg19(pretrained=True).features\n",
        "VGG.cuda()\n",
        "\n",
        "for i, layer in enumerate(VGG):\n",
        "    \n",
        "    if i in [0,5,10,19,21,28]:\n",
        "        VGG[i].register_forward_hook(get_features)\n",
        "    \n",
        "    elif isinstance(layer, nn.MaxPool2d):\n",
        "        VGG[i] = nn.AvgPool2d(kernel_size=2)\n",
        "\n",
        "VGG.eval()\n",
        "\n",
        "for p in VGG.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "features = []\n",
        "VGG(input_img.unsqueeze(0))\n",
        "c_target = features[4].detach()\n",
        "\n",
        "features = []\n",
        "VGG(style_img.unsqueeze(0))\n",
        "f_targets = features[:4]+features[5:]\n",
        "gram_targets = [gram_matrix(i).detach() for i in f_targets]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/checkpoints/vgg19-dcbb9e9d.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b4abbf9758a49349981e735824528a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=574673361), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwj8sQZJqQEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = 1\n",
        "beta = 1e3\n",
        "iterations = 200\n",
        "image = input_img.clone().unsqueeze(0)\n",
        "# image = torch.randn(1,3,512,512).cuda()\n",
        "images = []\n",
        "optimizer = optim.LBFGS([\n",
        "image.requires_grad_()], lr=1)    \n",
        "mse_loss = nn.MSELoss(reduction='mean')\n",
        "l_c = []\n",
        "l_s = []\n",
        "counter = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FU_mqdxqSlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f296aa40-e984-46a4-80ff-9ff060b05caf"
      },
      "source": [
        "for itr in range(iterations):\n",
        "\n",
        "    features = []\n",
        "    def closure():\n",
        "        optimizer.zero_grad()\n",
        "        VGG(image)\n",
        "        t_features = features[-6:]\n",
        "        content = t_features[4]\n",
        "        style_features = t_features[:4]+t_features[5:]\n",
        "        t_features = []\n",
        "        gram_styles = [gram_matrix(i) for i in style_features]\n",
        "        c_loss = alpha * mse_loss(content, c_target)\n",
        "        s_loss = 0\n",
        "\n",
        "        for i in range(5):\n",
        "            n_c = gram_styles[i].shape[0]\n",
        "            s_loss += beta * mse_loss(gram_styles[i],gram_targets[i])/(n_c**2)\n",
        "\n",
        "        total_loss = c_loss+s_loss\n",
        "\n",
        "        l_c.append(c_loss)\n",
        "        l_s.append(s_loss)\n",
        "        \n",
        "        total_loss.backward()\n",
        "        return total_loss\n",
        "\n",
        "    optimizer.step(closure)\n",
        "    \n",
        "    print('Step {}: S_loss: {:.8f} C_loss: {:.8f}'.format(itr, l_s[-1], l_c[-1]))\n",
        "    \n",
        "\n",
        "    if itr%1 == 0:\n",
        "        temp = unload(image[0].cpu().detach())\n",
        "        temp = to_image(temp)\n",
        "        temp = np.array(temp)\n",
        "        images.append(temp)\n",
        "        imageio.mimsave('progress.gif', images)\n",
        "        \n",
        "    \n",
        "    plt.clf()\n",
        "    plt.plot(l_c, label='Content Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss1.png')\n",
        "    \n",
        "    plt.clf()\n",
        "    plt.plot(l_s, label='Style Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss2.png')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 0: S_loss: 1.25150800 C_loss: 0.33708695\n",
            "Step 1: S_loss: 0.64550978 C_loss: 0.34221539\n",
            "Step 2: S_loss: 0.46952578 C_loss: 0.33885905\n",
            "Step 3: S_loss: 0.27503324 C_loss: 0.33305791\n",
            "Step 4: S_loss: 0.20436397 C_loss: 0.32720113\n",
            "Step 5: S_loss: 0.17740931 C_loss: 0.32171863\n",
            "Step 6: S_loss: 0.15246628 C_loss: 0.31732142\n",
            "Step 7: S_loss: 0.14044447 C_loss: 0.31320566\n",
            "Step 8: S_loss: 0.13439077 C_loss: 0.30925217\n",
            "Step 9: S_loss: 0.12504256 C_loss: 0.30660808\n",
            "Step 10: S_loss: 0.11790069 C_loss: 0.30369487\n",
            "Step 11: S_loss: 0.11227279 C_loss: 0.30032974\n",
            "Step 12: S_loss: 0.10695302 C_loss: 0.29818422\n",
            "Step 13: S_loss: 0.10298519 C_loss: 0.29619747\n",
            "Step 14: S_loss: 0.09972975 C_loss: 0.29441214\n",
            "Step 15: S_loss: 0.09676630 C_loss: 0.29291514\n",
            "Step 16: S_loss: 0.09406295 C_loss: 0.29170898\n",
            "Step 17: S_loss: 0.09202286 C_loss: 0.29042116\n",
            "Step 18: S_loss: 0.09034325 C_loss: 0.28928691\n",
            "Step 19: S_loss: 0.08866578 C_loss: 0.28813982\n",
            "Step 20: S_loss: 0.08709746 C_loss: 0.28716132\n",
            "Step 21: S_loss: 0.08566768 C_loss: 0.28624132\n",
            "Step 22: S_loss: 0.08452022 C_loss: 0.28528339\n",
            "Step 23: S_loss: 0.08329876 C_loss: 0.28464013\n",
            "Step 24: S_loss: 0.08228116 C_loss: 0.28399158\n",
            "Step 25: S_loss: 0.08127400 C_loss: 0.28331989\n",
            "Step 26: S_loss: 0.08024076 C_loss: 0.28275493\n",
            "Step 27: S_loss: 0.07928403 C_loss: 0.28216851\n",
            "Step 28: S_loss: 0.07853910 C_loss: 0.28157976\n",
            "Step 29: S_loss: 0.07774685 C_loss: 0.28106442\n",
            "Step 30: S_loss: 0.07696691 C_loss: 0.28058344\n",
            "Step 31: S_loss: 0.07631013 C_loss: 0.28020263\n",
            "Step 32: S_loss: 0.07570118 C_loss: 0.27984875\n",
            "Step 33: S_loss: 0.07524165 C_loss: 0.27935883\n",
            "Step 34: S_loss: 0.07469083 C_loss: 0.27912080\n",
            "Step 35: S_loss: 0.07421143 C_loss: 0.27877766\n",
            "Step 36: S_loss: 0.07380888 C_loss: 0.27847725\n",
            "Step 37: S_loss: 0.07348316 C_loss: 0.27818441\n",
            "Step 38: S_loss: 0.07317555 C_loss: 0.27790794\n",
            "Step 39: S_loss: 0.07291371 C_loss: 0.27760071\n",
            "Step 40: S_loss: 0.07259861 C_loss: 0.27741018\n",
            "Step 41: S_loss: 0.07241721 C_loss: 0.27714118\n",
            "Step 42: S_loss: 0.07219558 C_loss: 0.27695718\n",
            "Step 43: S_loss: 0.07199470 C_loss: 0.27678341\n",
            "Step 44: S_loss: 0.07185384 C_loss: 0.27658293\n",
            "Step 45: S_loss: 0.07169858 C_loss: 0.27641144\n",
            "Step 46: S_loss: 0.07156813 C_loss: 0.27622309\n",
            "Step 47: S_loss: 0.07141192 C_loss: 0.27610373\n",
            "Step 48: S_loss: 0.07128756 C_loss: 0.27597472\n",
            "Step 49: S_loss: 0.07116430 C_loss: 0.27586082\n",
            "Step 50: S_loss: 0.07107356 C_loss: 0.27572489\n",
            "Step 51: S_loss: 0.07096825 C_loss: 0.27562332\n",
            "Step 52: S_loss: 0.07086352 C_loss: 0.27553135\n",
            "Step 53: S_loss: 0.07076801 C_loss: 0.27544492\n",
            "Step 54: S_loss: 0.07069106 C_loss: 0.27535087\n",
            "Step 55: S_loss: 0.07060933 C_loss: 0.27526605\n",
            "Step 56: S_loss: 0.07053233 C_loss: 0.27518708\n",
            "Step 57: S_loss: 0.07046130 C_loss: 0.27510601\n",
            "Step 58: S_loss: 0.07040390 C_loss: 0.27502623\n",
            "Step 59: S_loss: 0.07034687 C_loss: 0.27495041\n",
            "Step 60: S_loss: 0.07027419 C_loss: 0.27489367\n",
            "Step 61: S_loss: 0.07022620 C_loss: 0.27482295\n",
            "Step 62: S_loss: 0.07017457 C_loss: 0.27475142\n",
            "Step 63: S_loss: 0.07012508 C_loss: 0.27468592\n",
            "Step 64: S_loss: 0.07007515 C_loss: 0.27462012\n",
            "Step 65: S_loss: 0.07002414 C_loss: 0.27456099\n",
            "Step 66: S_loss: 0.06998032 C_loss: 0.27450565\n",
            "Step 67: S_loss: 0.06993336 C_loss: 0.27445388\n",
            "Step 68: S_loss: 0.06988299 C_loss: 0.27440822\n",
            "Step 69: S_loss: 0.06983300 C_loss: 0.27436793\n",
            "Step 70: S_loss: 0.06978965 C_loss: 0.27431855\n",
            "Step 71: S_loss: 0.06975100 C_loss: 0.27426559\n",
            "Step 72: S_loss: 0.06971591 C_loss: 0.27421409\n",
            "Step 73: S_loss: 0.06966361 C_loss: 0.27417815\n",
            "Step 74: S_loss: 0.06963021 C_loss: 0.27412736\n",
            "Step 75: S_loss: 0.06959496 C_loss: 0.27408153\n",
            "Step 76: S_loss: 0.06955678 C_loss: 0.27403840\n",
            "Step 77: S_loss: 0.06952611 C_loss: 0.27399471\n",
            "Step 78: S_loss: 0.06950346 C_loss: 0.27394342\n",
            "Step 79: S_loss: 0.06948447 C_loss: 0.27389136\n",
            "Step 80: S_loss: 0.06946203 C_loss: 0.27384460\n",
            "Step 81: S_loss: 0.06943101 C_loss: 0.27380705\n",
            "Step 82: S_loss: 0.06940016 C_loss: 0.27377287\n",
            "Step 83: S_loss: 0.06937727 C_loss: 0.27372867\n",
            "Step 84: S_loss: 0.06934848 C_loss: 0.27369106\n",
            "Step 85: S_loss: 0.06932177 C_loss: 0.27365297\n",
            "Step 86: S_loss: 0.06929566 C_loss: 0.27361518\n",
            "Step 87: S_loss: 0.06927114 C_loss: 0.27358246\n",
            "Step 88: S_loss: 0.06924599 C_loss: 0.27354664\n",
            "Step 89: S_loss: 0.06922443 C_loss: 0.27350715\n",
            "Step 90: S_loss: 0.06919941 C_loss: 0.27347308\n",
            "Step 91: S_loss: 0.06918187 C_loss: 0.27343404\n",
            "Step 92: S_loss: 0.06915975 C_loss: 0.27340445\n",
            "Step 93: S_loss: 0.06913231 C_loss: 0.27337855\n",
            "Step 94: S_loss: 0.06910763 C_loss: 0.27335086\n",
            "Step 95: S_loss: 0.06908648 C_loss: 0.27332175\n",
            "Step 96: S_loss: 0.06907120 C_loss: 0.27328798\n",
            "Step 97: S_loss: 0.06905848 C_loss: 0.27325505\n",
            "Step 98: S_loss: 0.06903897 C_loss: 0.27322826\n",
            "Step 99: S_loss: 0.06900955 C_loss: 0.27321222\n",
            "Step 100: S_loss: 0.06898566 C_loss: 0.27319074\n",
            "Step 101: S_loss: 0.06896518 C_loss: 0.27316552\n",
            "Step 102: S_loss: 0.06895123 C_loss: 0.27313438\n",
            "Step 103: S_loss: 0.06893130 C_loss: 0.27311248\n",
            "Step 104: S_loss: 0.06891017 C_loss: 0.27309126\n",
            "Step 105: S_loss: 0.06889135 C_loss: 0.27306795\n",
            "Step 106: S_loss: 0.06886931 C_loss: 0.27304929\n",
            "Step 107: S_loss: 0.06885061 C_loss: 0.27302906\n",
            "Step 108: S_loss: 0.06883737 C_loss: 0.27300555\n",
            "Step 109: S_loss: 0.06882128 C_loss: 0.27298450\n",
            "Step 110: S_loss: 0.06880163 C_loss: 0.27296817\n",
            "Step 111: S_loss: 0.06878576 C_loss: 0.27294961\n",
            "Step 112: S_loss: 0.06877121 C_loss: 0.27293074\n",
            "Step 113: S_loss: 0.06875455 C_loss: 0.27291590\n",
            "Step 114: S_loss: 0.06873818 C_loss: 0.27290061\n",
            "Step 115: S_loss: 0.06872764 C_loss: 0.27287829\n",
            "Step 116: S_loss: 0.06870754 C_loss: 0.27286643\n",
            "Step 117: S_loss: 0.06868663 C_loss: 0.27285647\n",
            "Step 118: S_loss: 0.06867126 C_loss: 0.27284133\n",
            "Step 119: S_loss: 0.06866425 C_loss: 0.27281833\n",
            "Step 120: S_loss: 0.06865145 C_loss: 0.27280158\n",
            "Step 121: S_loss: 0.06863777 C_loss: 0.27278620\n",
            "Step 122: S_loss: 0.06862463 C_loss: 0.27277052\n",
            "Step 123: S_loss: 0.06861214 C_loss: 0.27275544\n",
            "Step 124: S_loss: 0.06859953 C_loss: 0.27274090\n",
            "Step 125: S_loss: 0.06858677 C_loss: 0.27272660\n",
            "Step 126: S_loss: 0.06857618 C_loss: 0.27271071\n",
            "Step 127: S_loss: 0.06856413 C_loss: 0.27269682\n",
            "Step 128: S_loss: 0.06855066 C_loss: 0.27268517\n",
            "Step 129: S_loss: 0.06854097 C_loss: 0.27267027\n",
            "Step 130: S_loss: 0.06853417 C_loss: 0.27265278\n",
            "Step 131: S_loss: 0.06852727 C_loss: 0.27263522\n",
            "Step 132: S_loss: 0.06851547 C_loss: 0.27262366\n",
            "Step 133: S_loss: 0.06850576 C_loss: 0.27261049\n",
            "Step 134: S_loss: 0.06849748 C_loss: 0.27259666\n",
            "Step 135: S_loss: 0.06848724 C_loss: 0.27258539\n",
            "Step 136: S_loss: 0.06847774 C_loss: 0.27257431\n",
            "Step 137: S_loss: 0.06846964 C_loss: 0.27256233\n",
            "Step 138: S_loss: 0.06846292 C_loss: 0.27254921\n",
            "Step 139: S_loss: 0.06845672 C_loss: 0.27253574\n",
            "Step 140: S_loss: 0.06844842 C_loss: 0.27252471\n",
            "Step 141: S_loss: 0.06844305 C_loss: 0.27251095\n",
            "Step 142: S_loss: 0.06843667 C_loss: 0.27249843\n",
            "Step 143: S_loss: 0.06843262 C_loss: 0.27248412\n",
            "Step 144: S_loss: 0.06842756 C_loss: 0.27247122\n",
            "Step 145: S_loss: 0.06841940 C_loss: 0.27246153\n",
            "Step 146: S_loss: 0.06841260 C_loss: 0.27245116\n",
            "Step 147: S_loss: 0.06840488 C_loss: 0.27244166\n",
            "Step 148: S_loss: 0.06839810 C_loss: 0.27243128\n",
            "Step 149: S_loss: 0.06839508 C_loss: 0.27241778\n",
            "Step 150: S_loss: 0.06838820 C_loss: 0.27240849\n",
            "Step 151: S_loss: 0.06838259 C_loss: 0.27239829\n",
            "Step 152: S_loss: 0.06837917 C_loss: 0.27238628\n",
            "Step 153: S_loss: 0.06837259 C_loss: 0.27237785\n",
            "Step 154: S_loss: 0.06836647 C_loss: 0.27236962\n",
            "Step 155: S_loss: 0.06836049 C_loss: 0.27236146\n",
            "Step 156: S_loss: 0.06835607 C_loss: 0.27235207\n",
            "Step 157: S_loss: 0.06835382 C_loss: 0.27234057\n",
            "Step 158: S_loss: 0.06834877 C_loss: 0.27233219\n",
            "Step 159: S_loss: 0.06834579 C_loss: 0.27232188\n",
            "Step 160: S_loss: 0.06834072 C_loss: 0.27231365\n",
            "Step 161: S_loss: 0.06833288 C_loss: 0.27230841\n",
            "Step 162: S_loss: 0.06832667 C_loss: 0.27230188\n",
            "Step 163: S_loss: 0.06832298 C_loss: 0.27229327\n",
            "Step 164: S_loss: 0.06831744 C_loss: 0.27228665\n",
            "Step 165: S_loss: 0.06831110 C_loss: 0.27228072\n",
            "Step 166: S_loss: 0.06830448 C_loss: 0.27227533\n",
            "Step 167: S_loss: 0.06830046 C_loss: 0.27226752\n",
            "Step 168: S_loss: 0.06829702 C_loss: 0.27225941\n",
            "Step 169: S_loss: 0.06829144 C_loss: 0.27225372\n",
            "Step 170: S_loss: 0.06828595 C_loss: 0.27224827\n",
            "Step 171: S_loss: 0.06828330 C_loss: 0.27223983\n",
            "Step 172: S_loss: 0.06827734 C_loss: 0.27223432\n",
            "Step 173: S_loss: 0.06827397 C_loss: 0.27222627\n",
            "Step 174: S_loss: 0.06827132 C_loss: 0.27221757\n",
            "Step 175: S_loss: 0.06826899 C_loss: 0.27220875\n",
            "Step 176: S_loss: 0.06826381 C_loss: 0.27220309\n",
            "Step 177: S_loss: 0.06825965 C_loss: 0.27219644\n",
            "Step 178: S_loss: 0.06825701 C_loss: 0.27218857\n",
            "Step 179: S_loss: 0.06825285 C_loss: 0.27218258\n",
            "Step 180: S_loss: 0.06825005 C_loss: 0.27217531\n",
            "Step 181: S_loss: 0.06824741 C_loss: 0.27216765\n",
            "Step 182: S_loss: 0.06824525 C_loss: 0.27215970\n",
            "Step 183: S_loss: 0.06824360 C_loss: 0.27215129\n",
            "Step 184: S_loss: 0.06824303 C_loss: 0.27214199\n",
            "Step 185: S_loss: 0.06824108 C_loss: 0.27213421\n",
            "Step 186: S_loss: 0.06823535 C_loss: 0.27213043\n",
            "Step 187: S_loss: 0.06823199 C_loss: 0.27212420\n",
            "Step 188: S_loss: 0.06822640 C_loss: 0.27212036\n",
            "Step 189: S_loss: 0.06822307 C_loss: 0.27211437\n",
            "Step 190: S_loss: 0.06822000 C_loss: 0.27210835\n",
            "Step 191: S_loss: 0.06821796 C_loss: 0.27210134\n",
            "Step 192: S_loss: 0.06821544 C_loss: 0.27209491\n",
            "Step 193: S_loss: 0.06821123 C_loss: 0.27209014\n",
            "Step 194: S_loss: 0.06820829 C_loss: 0.27208441\n",
            "Step 195: S_loss: 0.06820519 C_loss: 0.27207917\n",
            "Step 196: S_loss: 0.06820040 C_loss: 0.27207583\n",
            "Step 197: S_loss: 0.06819735 C_loss: 0.27207094\n",
            "Step 198: S_loss: 0.06819630 C_loss: 0.27206427\n",
            "Step 199: S_loss: 0.06819224 C_loss: 0.27206066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYPElEQVR4nO3dfXBddZ3H8c83DzTFBFua2C0USVFY\npLSmnfA01VqKQnlYwRlHdBwefCqzPgK7s1tkWKq7sCgKyAyjhrVQVhTx2a3sWsBoZZYtpDWUQgsF\nrENqpaW1tl0WbJPv/nF/556bnKS5ubkP+en7NZO555577j3fntx+8rvfc+455u4CAMSnrtYFAABK\nQ4ADQKQIcACIFAEOAJEiwAEgUg3VXFlra6u3t7dXc5UAEL1169a97O5tQ+dXNcDb29vV09NTzVUC\nQPTM7LfDzaeFAgCRIsABIFIEOABEqqo9cAB/Pg4cOKC+vj69+uqrtS7lz0ZTU5NmzpypxsbGopYn\nwAGUpK+vTy0tLWpvb5eZ1bqc6Lm7du3apb6+Ps2aNauo59BCAVCSV199VdOmTSO8y8TMNG3atDF9\nohk1wM2sycweM7MnzOwpM/tcmD/LzNaa2XNm9h0zO2wctQOIEOFdXmPdnsWMwF+TtNjd3yqpQ9IS\nMztd0hck3erub5b0B0kfGWOtRVv3292659GtlXp5AIjSqAHuOfvD3cbw45IWS/pemL9S0kUVqVDS\nHd3P659XPV2plwcQqRtuuEGzZ8/W3Llz1dHRobVr10qSbrvtNr3yyiujPr+5uXlM62tvb9fLL79c\nUq2VUFQP3MzqzaxX0g5JD0p6XtIedz8YFumTdPQIz11qZj1m1rNz586Sijz56NfrQD8XngCQevTR\nR7Vq1SqtX79eGzZs0EMPPaRjjjlGUvEBHruiAtzd+929Q9JMSadKOrHYFbh7l7t3untnW1vmq/wA\nUJLt27ertbVVkyZNkiS1trbqqKOO0u23367f/e53OvPMM3XmmWdqxYoVuvLKK/PPu/POO3XVVVdl\nXu/mm2/WKaecorlz5+r6668vuo7du3froosu0ty5c3X66adrw4YNkqRf/vKX6ujoUEdHh+bNm6d9\n+/Zp+/btWrhwoTo6OnTyySfrV7/61bi2wZgOI3T3PWbWLekMSVPMrCGMwmdK2jauSg6B3STAxPa5\n/3hKT/9ub1lf86SjjtD1fzN7xMfPPvtsff7zn9cJJ5ygd77znbr44ov1jne8Q5/+9Kd1yy23qLu7\nW62trdq/f79uuOEG3XzzzWpsbNRdd92lr3/964Nea/Xq1dqyZYsee+wxubve/e53a82aNVq4cOGo\ndV5//fWaN2+efvSjH+nnP/+5Lr30UvX29upLX/qS7rjjDi1YsED79+9XU1OTurq6dM455+jaa69V\nf3//uD8lFHMUSpuZTQnTkyW9S9ImSd2S3hsWu0zSj8dVSRG4fieARHNzs9atW6euri61tbXp4osv\n1t133z3scosXL9aqVau0efNmHThwQHPmzBm0zOrVq7V69WrNmzdP8+fP1+bNm7Vly5ai6njkkUd0\nySWXSJIWL16sXbt2ae/evVqwYIGuvvpq3X777dqzZ48aGhp0yimn6K677tLy5cv15JNPqqWlZVzb\noJgR+AxJK82sXrnAv9/dV5nZ05LuM7N/kfRrSd8YVyWHwJFKwMR2qJFyJdXX12vRokVatGiR5syZ\no5UrV+ryyy/PLPfRj35UN954o0488UR96EMfyjzu7rrmmmt0xRVXlK22ZcuW6fzzz9cDDzygBQsW\n6Gc/+5kWLlyoNWvW6Kc//akuv/xyXX311br00ktLXseoAe7uGyTNG2b+C8r1w6vGnTAHkPPMM8+o\nrq5Oxx9/vCSpt7dXxx57rCSppaVF+/btU2trqyTptNNO04svvpjf4TnUOeeco+uuu04f/OAH1dzc\nrG3btqmxsVFveMMbRq3j7W9/u+69915dd911+sUvfqHW1lYdccQRev755zVnzhzNmTNHjz/+uDZv\n3qzJkydr5syZ+tjHPqbXXntN69evr2yATwRGFxzAEPv379enPvWpfHvizW9+s7q6uiRJS5cu1ZIl\nS3TUUUepu7tbkvS+971Pvb29mjp1aua1zj77bG3atElnnHGGpFzb5Zvf/OawAT537lzV1dXlX3P5\n8uX68Ic/rLlz5+rwww/XypUrJeWOhOnu7lZdXZ1mz56tc889V/fdd1++F9/c3Kx77rlnXNvAqtlX\n7uzs9FIu6PCVh7bo1oee1fM3nqf6OsIcmAg2bdqkt7zlLbUuo2gXXHCBrrrqKp111lm1LuWQhtuu\nZrbO3TuHLhvFuVBomwAo1Z49e3TCCSdo8uTJEz68xyqKFkoi92mBNAdQvClTpujZZ5+tdRkVEccI\nvNYFABgWh/aW11i3ZxQBnuCtAkwcTU1N2rVrFyFeJsn5wJuamop+ThQtFHrgwMQzc+ZM9fX1qdRz\nHCEruSJPsaII8AR/6IGJo7Gxsegrx6AyomihcNJ4AMiKIsATThccAPKiCnAAQCqqAKcHDgCpKAKc\nFjgAZEUR4ACArCgCnLMRAkBWFAGeoAcOAKkoApweOABkRRHgCY4DB4BUFAHOABwAsqII8AQ9cABI\nRRHg9MABICuKAE8wAAeAVBQBznHgAJA1aoCb2TFm1m1mT5vZU2b2mTB/uZltM7Pe8HNe5csFACSK\nuaDDQUl/5+7rzaxF0jozezA8dqu7f6ly5Q3GpZsAIDVqgLv7dknbw/Q+M9sk6ehKF1aInZgAkDWm\nHriZtUuaJ2ltmPVJM9tgZivMbGqZa8tg/A0AqaID3MyaJX1f0pXuvlfSVyW9SVKHciP0L4/wvKVm\n1mNmPVz8FADKp6gAN7NG5cL7Xnf/gSS5+0vu3u/uA5LulHTqcM919y5373T3zra2tnEVSwscAFLF\nHIVikr4haZO731Iwf0bBYu+RtLH85eXXVamXBoBoFXMUygJJl0h60sx6w7zPSvqAmXUo15reKumK\nilRYiBE4AOQVcxTKIxr+fFIPlL+c4TH+BoCsKL6JmeB0sgCQiiLAaYEDQFYUAZ7gKBQASEUR4AzA\nASArigBPMAAHgFQUAc5x4ACQFUWAJzgbIQCkoghwBuAAkBVFgCcYfwNAKooAZwAOAFlRBHiCFjgA\npOIIcJrgAJARR4AHnAsFAFJRBDjjbwDIiiLA8xiAA0BeFAFOCxwAsqII8AQDcABIRRHgRhccADKi\nCPAEx4EDQCqKAKcHDgBZUQR4guPAASAVRYAzAAeArCgCPEEPHABSUQQ4PXAAyBo1wM3sGDPrNrOn\nzewpM/tMmH+kmT1oZlvC7dRKF8sAHABSxYzAD0r6O3c/SdLpkj5hZidJWibpYXc/XtLD4X5FcBw4\nAGSNGuDuvt3d14fpfZI2STpa0oWSVobFVkq6qFJFFtRS6VUAQDTG1AM3s3ZJ8yStlTTd3beHh34v\naXpZKxu04oq9MgBEq+gAN7NmSd+XdKW77y18zHND42GHx2a21Mx6zKxn586d4yqWATgApIoKcDNr\nVC6873X3H4TZL5nZjPD4DEk7hnuuu3e5e6e7d7a1tZVUJANwAMgq5igUk/QNSZvc/ZaCh34i6bIw\nfZmkH5e/PADASBqKWGaBpEskPWlmvWHeZyXdJOl+M/uIpN9Kel9lSpSMA8EBIGPUAHf3RzRyF+Os\n8pYzWi3VXBsATGxxfBOz1gUAwAQURYADALKiCnBOJwsAqSgCnH2YAJAVRYAn2IkJAKkoApwROABk\nRRHgCQbgAJCKIsA5nSwAZEUR4AlOJwsAqSgCnB44AGRFEeAJxt8AkIoqwAEAqagCnBY4AKSiCHBO\nJwsAWVEEeIohOAAkoghwxt8AkBVFgCfogQNAKooApwUOAFlRBHiCATgApKIIcM6FAgBZUQR4gh44\nAKSiCHB64ACQFUWAJ7gmJgCkoghwBuAAkDVqgJvZCjPbYWYbC+YtN7NtZtYbfs6rbJk59MABIFXM\nCPxuSUuGmX+ru3eEnwfKW9Zg9MABIGvUAHf3NZJ2V6GWUTECB4DUeHrgnzSzDaHFMrVsFQ2LITgA\nDFVqgH9V0pskdUjaLunLIy1oZkvNrMfMenbu3Fni6nI4CgUAUiUFuLu/5O797j4g6U5Jpx5i2S53\n73T3zra2tpKKpAcOAFklBbiZzSi4+x5JG0datpzogQNAqmG0Bczs25IWSWo1sz5J10taZGYdyp1f\naqukKypYIx1wABjGqAHu7h8YZvY3KlALAGAM4vgmJk1wAMiIIsAT9MABIBVFgDP+BoCsKAI8wXHg\nAJCKIsBpgQNAVhQBnqAHDgCpKAKcETgAZEUR4AkG4ACQiiLAuSo9AGRFEeAJpwkOAHlxBDgDcADI\niCPAAQAZUQU4DRQASEUR4HRQACArjgAPB4KzExMAUnEEeLglvwEgFUeAhwQnvwEgFUeAK2mh1LgQ\nAJhA4gjwZAROggNAXhwBHm6JbwBIxRHgRgsFAIaKJMBzt7RQACAVR4CHW+IbAFJxBDgtFADIGDXA\nzWyFme0ws40F8440swfNbEu4nVrJItPjwElwAEgUMwK/W9KSIfOWSXrY3Y+X9HC4XzF1+R54JdcC\nAHEZNcDdfY2k3UNmXyhpZZheKemiMtc1RC7BB0hwAMgrtQc+3d23h+nfS5o+0oJmttTMesysZ+fO\nnSWtjK/SA0DWuHdieu7YvhGz1d273L3T3Tvb2tpKWkf+dLIkOADklRrgL5nZDEkKtzvKV1JW/igU\nEhwA8koN8J9IuixMXybpx+UpZ3icThYAsoo5jPDbkh6V9Ndm1mdmH5F0k6R3mdkWSe8M9ytXJMeB\nA0BGw2gLuPsHRnjorDLXMqJkJyZHoQBAKopvYiaIbwBIRRHgxhd5ACAjjgDndFYAkBFFgNeFKhmB\nA0AqigC3/Ffpa1wIAEwgcQQ4ZyMEgIw4Ajzc0kIBgFQcAc7JrAAgI4oAT8bgXBMTAFJRBHidjb4M\nAPyliSLAk7MR8lV6AEjFEeDhlvwGgFQcAc5X6QEgI44AT3Zi1rgOAJhI4gjw/AicCAeARGQBXts6\nAGAiiSTAuSYmAAwVR4CHW0bgAJCKI8D5Kj0AZMQR4OKixgAwVBQBXsfpZAEgI4oAV/6q9LUtAwAm\nkigCPH9NTHooAJAXR4CzExMAMhrG82Qz2yppn6R+SQfdvbMcRWXWE24ZgANAalwBHpzp7i+X4XVG\nlP8iDwkOAHlRtFDqaKEAQMZ4A9wlrTazdWa2dLgFzGypmfWYWc/OnTtLWkmyE5OjUAAgNd4Af5u7\nz5d0rqRPmNnCoQu4e5e7d7p7Z1tbW2lr4WyEAJAxrgB3923hdoekH0o6tRxFDWVcExMAMkoOcDN7\nnZm1JNOSzpa0sVyFFarjmpgAkDGeo1CmS/phOEKkQdK33P2/ylLVEA1hL+ZBmuAAkFdygLv7C5Le\nWsZaRpQEeH8/AQ4AiSgOI6wPAX6AETgA5EUR4Gam+jpT/8BArUsBgAkjigCXcm0UeuAAkIorwOmB\nA0BeNAGea6EQ4ACQiCbAG+vrdJAeOADkRRPg9bRQAGCQaAKcnZgAMFg8AV5fRw8cAArEE+CMwAFg\nkGgCPNcDZycmACSiCfAphzdq1//+qdZlAMCEEU2ATz38MO39vwO1LgMAJoxoAvyIyY0EOAAUiCbA\nW5oatO/Vg7UuAwAmjGgC/IimRu177SCHEgJAEE2ATz28UZL0h1fYkQkAUkQBflxbsyTpuR37a1wJ\nAEwM0QT48dNzAb6FAAcASREF+F8d0aSWSQ3a8tK+WpcCABNCNAFuZjp+erM29P2x1qUAwIQQTYBL\n0intR6r3xT36h+89UetSAKDmogrwD552rCTp/p4+9f3hlRpXAwC1FVWAv3Ha4fnpt32hWy/uJsQB\n/OUaV4Cb2RIze8bMnjOzZeUq6lB+86/n5aff/sVutS/7qdz5cg+AvzxWaviZWb2kZyW9S1KfpMcl\nfcDdnx7pOZ2dnd7T01PS+gq5u2Zd88CgeWccN03zj52iN7Q06fWTG3X4YfWa1FivxjpTQ32dGupN\njXXhtt7UkJ+uU0NYJpnfWG8ys3HXCQDlYGbr3L1z6PyGcbzmqZKec/cXwgruk3ShpBEDvFzMTFtv\nOl/PvrRPZ9+6RpL06Au79NjW3WX7qn19nanOcusySXVmMpMsrF/KTScTybSF5ZLHC5e1wieE++nz\nJBt2fvqHJP+6IyxbKZX+Y1bxP5UVXkHs2x/VceN75ujUWUeW9TXHE+BHS3qx4H6fpNOGLmRmSyUt\nlaQ3vvGN41hd1gnTW7T1pvPz9wcGXLtf+ZP2/t8BvfKnfr12sF8H+l0H+10HBgZ0sN91sH9ABwZy\nt4XzD/QP6GCYf6DfdXBgQO7SgOdG/B5eP/nzkHxwcbkKP8Qkn2h8hGUGP9/z0yMtWzg/mZm+RlpP\npVS6O1X5+iu7hoo37+gO/tl43aT6sr/meAK8KO7eJalLyrVQKrmuujpTa/MktTZPquRqAGBCGM9O\nzG2Sjim4PzPMAwBUwXgC/HFJx5vZLDM7TNL7Jf2kPGUBAEZTcgvF3Q+a2Scl/UxSvaQV7v5U2SoD\nABzSuHrg7v6ApAdGXRAAUHZRfRMTAJAiwAEgUgQ4AESKAAeASJV8LpSSVma2U9JvS3x6q6SXy1hO\nuVDX2FDX2FDX2E3U2sZT17Hu3jZ0ZlUDfDzMrGe4k7nUGnWNDXWNDXWN3UStrRJ10UIBgEgR4AAQ\nqZgCvKvWBYyAusaGusaGusZuotZW9rqi6YEDAAaLaQQOAChAgANApKII8FpcPHnI+rea2ZNm1mtm\nPWHekWb2oJltCbdTw3wzs9tDrRvMbH4Z61hhZjvMbGPBvDHXYWaXheW3mNllFapruZltC9us18zO\nK3jsmlDXM2Z2TsH8sv6ezewYM+s2s6fN7Ckz+0yYX9Ntdoi6arrNzKzJzB4zsydCXZ8L82eZ2dqw\nju+E00fLzCaF+8+Fx9tHq7fMdd1tZr8p2F4dYX7V3vvhNevN7Ndmtircr972cvcJ/aPcqWqfl3Sc\npMMkPSHppCrXsFVS65B5X5S0LEwvk/SFMH2epP9U7lKJp0taW8Y6FkqaL2ljqXVIOlLSC+F2apie\nWoG6lkv6+2GWPSn8DidJmhV+t/WV+D1LmiFpfphuUe4i3CfVepsdoq6abrPw724O042S1obtcL+k\n94f5X5P0t2H645K+FqbfL+k7h6q3AnXdLem9wyxftfd+eN2rJX1L0qpwv2rbK4YReP7iye7+J0nJ\nxZNr7UJJK8P0SkkXFcy/x3P+R9IUM5tRjhW6+xpJu8dZxzmSHnT33e7+B0kPSlpSgbpGcqGk+9z9\nNXf/jaTnlPsdl/337O7b3X19mN4naZNy13Kt6TY7RF0jqco2C//u/eFuY/hxSYslfS/MH7q9ku34\nPUlnmZkdot5y1zWSqr33zWympPMl/Vu4b6ri9oohwIe7ePKh3uyV4JJWm9k6y12kWZKmu/v2MP17\nSdPDdLXrHWsd1azvk+Ej7IqkTVGrusLH1XnKjd4mzDYbUpdU420W2gG9knYoF3DPS9rj7geHWUd+\n/eHxP0qaVo263D3ZXjeE7XWrmSUXw63m7/E2Sf8gaSDcn6Yqbq8YAnwieJu7z5d0rqRPmNnCwgc9\n9zmo5sdjTpQ6gq9KepOkDknbJX25VoWYWbOk70u60t33Fj5Wy202TF0132bu3u/uHcpd4/ZUSSdW\nu4bhDK3LzE6WdI1y9Z2iXFvkH6tZk5ldIGmHu6+r5noLxRDgNb94srtvC7c7JP1QuTf2S0lrJNzu\nCItXu96x1lGV+tz9pfCfbkDSnUo/Ela1LjNrVC4k73X3H4TZNd9mw9U1UbZZqGWPpG5JZyjXgkiu\n3lW4jvz6w+Ovl7SrSnUtCa0od/fXJN2l6m+vBZLebWZblWtfLZb0FVVze423gV/pH+Uu+/aCcs39\nZEfN7Cqu/3WSWgqm/1u5vtnNGrwj7Ith+nwN3oHyWJnradfgnYVjqkO5kcpvlNuJMzVMH1mBumYU\nTF+lXI9PkmZr8A6bF5TbGVf233P4t98j6bYh82u6zQ5RV023maQ2SVPC9GRJv5J0gaTvavBOuY+H\n6U9o8E65+w9VbwXqmlGwPW+TdFMt3vvhtRcp3YlZte1VtmCp5I9ye5WfVa4fd22V131c2LhPSHoq\nWb9yvauHJW2R9FDyRghvmjtCrU9K6ixjLd9W7qP1AeX6ZB8ppQ5JH1ZuR8lzkj5Uobr+Pax3g6Sf\naHA4XRvqekbSuZX6PUt6m3LtkQ2SesPPebXeZoeoq6bbTNJcSb8O698o6Z8K/g88Fv7t35U0Kcxv\nCvefC48fN1q9Za7r52F7bZT0TaVHqlTtvV/wuouUBnjVthdfpQeASMXQAwcADIMAB4BIEeAAECkC\nHAAiRYADQKQIcACIFAEOAJH6f++/JHMjWbfEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElHbyOVY8tCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imsave('last.jpg',images[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvPI77BDU3fD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(images[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}